{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data  # features\n",
    "y = data.target  # target labels (0 for malignant, 1 for benign)\n",
    "\n",
    "# Optionally, display the description - uncomment the following line to do so\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    z = np.clip( x, -500, 500 )           # protect against overflow\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_logistic(X, y, w, b, lambda_=0, safe=False):\n",
    "    \"\"\"\n",
    "    Computes cost using logistic loss, non-matrix version\n",
    "\n",
    "    Args:\n",
    "      X (ndarray): Shape (m,n)  matrix of examples with n features\n",
    "      y (ndarray): Shape (m,)   target values\n",
    "      w (ndarray): Shape (n,)   parameters for prediction\n",
    "      b (scalar):               parameter  for prediction\n",
    "      lambda_ : (scalar, float) Controls amount of regularization, 0 = no regularization\n",
    "      safe : (boolean)          True-selects under/overflow safe algorithm\n",
    "    Returns:\n",
    "      cost (scalar): cost\n",
    "    \"\"\"\n",
    "\n",
    "    m,n = X.shape\n",
    "    cost = 0.0\n",
    "    for i in range(m):\n",
    "        z_i    = np.dot(X[i],w) + b                                             #(n,)(n,) or (n,) ()\n",
    "        if safe:  #avoids overflows\n",
    "            cost += -(y[i] * z_i ) + log_1pexp(z_i)\n",
    "        else:\n",
    "            f_wb_i = sigmoid(z_i)                                                   #(n,)\n",
    "            # cost  += -y[i] * np.log(f_wb_i) - (1 - y[i]) * np.log(1 - f_wb_i)       # scalar\n",
    "            cost += -y[i] * np.log(f_wb_i + 1e-10) - (1 - y[i]) * np.log(1 - f_wb_i + 1e-10)\n",
    "    cost = cost/m\n",
    "\n",
    "    reg_cost = 0\n",
    "    if lambda_ != 0:\n",
    "        for j in range(n):\n",
    "            reg_cost += (w[j]**2)                                               # scalar\n",
    "        reg_cost = (lambda_/(2*m))*reg_cost\n",
    "\n",
    "    return cost + reg_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_gradient_for_loop(X, y, w, b):\n",
    "    m, n = X.shape\n",
    "    dw = np.zeros((n,))  # initialize the gradient vector\n",
    "    db = 0.              # initialize the intercept gradient\n",
    "    \n",
    "    for i in range(m):\n",
    "        z = np.dot(X[i], w) + b\n",
    "        a = sigmoid(z)\n",
    "        dz = a - y[i]\n",
    "        for j in range(n):\n",
    "            dw[j] += X[i][j] * dz\n",
    "        db += dz\n",
    "    return dw / m, db / m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math\n",
    "\n",
    "def logistic_model(X, y, w_initial, b_initial, learning_rate=0.01, num_iterations=1000):\n",
    "    J_history = []\n",
    "    w = copy.deepcopy(w_initial)\n",
    "    b = b_initial\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # Calculate the predicted values\n",
    "        dw, db = calculate_gradient_for_loop(X, y, w, b)\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "    \n",
    "            # Save cost J at each iteration\n",
    "        if i<100000:      # prevent resource exhaustion \n",
    "            J_history.append( compute_cost_logistic(X, y, w, b) )\n",
    "\n",
    "        # Print cost every at intervals 10 times or as many iterations if < 10\n",
    "        if i% math.ceil(num_iterations / 10) == 0:\n",
    "            print(f\"Iteration {i:4d}: Cost {J_history[-1]}   \")    \n",
    "    return w, b, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 14.473392013068214   \n",
      "Iteration  100: Cost 6.730633348681038   \n",
      "Iteration  200: Cost 2.3784944915744997   \n",
      "Iteration  300: Cost 2.4196300261105126   \n",
      "Iteration  400: Cost 2.3785903387156364   \n",
      "Iteration  500: Cost 2.0934272515705215   \n",
      "Iteration  600: Cost 2.0748486389189518   \n",
      "Iteration  700: Cost 2.024430062676937   \n",
      "Iteration  800: Cost 2.0242506311123405   \n",
      "Iteration  900: Cost 2.0247204090993542   \n",
      "\n",
      "updated parameters: w:[ 6.46690480e+00  8.43467282e+00  3.75623407e+01  1.54548934e+01\n",
      "  5.81674010e-02 -2.97686511e-02 -1.18255340e-01 -5.05056037e-02\n",
      "  1.09511609e-01  4.68675301e-02  2.49197574e-02  6.14996934e-01\n",
      " -1.62778507e-01 -1.63074093e+01  3.07015386e-03 -6.83128692e-03\n",
      " -1.33559014e-02 -1.69507873e-03  9.84419097e-03  1.00396016e-03\n",
      "  6.80168708e+00  1.05233822e+01  3.79435181e+01 -2.23383434e+01\n",
      "  7.12320217e-02 -1.29573704e-01 -2.53849976e-01 -5.90139852e-02\n",
      "  1.40974821e-01  4.29193121e-02], b:0.8453572267314364\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "w_tmp  = np.zeros_like(train_X[0])\n",
    "b_tmp  = 0.\n",
    "alpha = 0.1\n",
    "iters = 1000\n",
    "\n",
    "w_out, b_out, history = logistic_model(train_X, train_y, w_tmp, b_tmp, alpha, iters) \n",
    "\n",
    "print(f\"\\nupdated parameters: w:{w_out}, b:{b_out}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
